{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "# import torch\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = YOLO('yolo11n.pt')\n",
    "pose_model = YOLO('yolo11n-pose.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_for_detector(frame, target_size=640):\n",
    "    \"\"\"\n",
    "    Preprocess the input image for the object detector.\n",
    "    Resize, convert color, normalize, and convert to tensor.\n",
    "    \"\"\"\n",
    "    # Resize image (assuming detector expects 640x640)\n",
    "    frame_resized = cv2.resize(frame, (target_size, target_size))\n",
    "    # Convert BGR to RGB\n",
    "    frame_rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)\n",
    "    # Convert to float and normalize to [0, 1]\n",
    "    tensor = torch.from_numpy(frame_rgb).permute(2, 0, 1).float() / 255.0\n",
    "    tensor = tensor.unsqueeze(0)  # Add batch dimension\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_for_pose(roi, target_size=256):\n",
    "    \"\"\"\n",
    "    Preprocess the cropped region for the pose model.\n",
    "    Resize the ROI to the pose model's expected input size,\n",
    "    convert to tensor, and normalize.\n",
    "    \"\"\"\n",
    "    roi_resized = cv2.resize(roi, (target_size, target_size))\n",
    "    roi_rgb = cv2.cvtColor(roi_resized, cv2.COLOR_BGR2RGB)\n",
    "    tensor = torch.from_numpy(roi_rgb).permute(2, 0, 1).float() / 255.0\n",
    "    tensor = tensor.unsqueeze(0)\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_detector(model, input_tensor, conf_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Run the object detector and filter detections for the human class.\n",
    "    Here we assume:\n",
    "      - The model output is a dictionary with keys: 'boxes', 'scores', 'labels'.\n",
    "      - Class index 0 corresponds to 'human'.\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_tensor)\n",
    "    # Convert outputs to numpy (this depends on your model API)\n",
    "    boxes = outputs['boxes'].cpu().numpy()   # shape (N, 4) [x1, y1, x2, y2]\n",
    "    scores = outputs['scores'].cpu().numpy()   # shape (N,)\n",
    "    labels = outputs['labels'].cpu().numpy()   # shape (N,)\n",
    "    \n",
    "    detections = []\n",
    "    for bbox, score, label in zip(boxes, scores, labels):\n",
    "        if label == 0 and score >= conf_threshold:  # Filter for human detections\n",
    "            detections.append({'bbox': bbox, 'score': score, 'class': 'human'})\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pose_model(model, input_tensor):\n",
    "    \"\"\"\n",
    "    Run the pose model on the input tensor.\n",
    "    Assume the output is a dictionary with a key 'keypoints' that returns\n",
    "    an array of shape (1, num_keypoints, 2) with coordinates in the resized ROI.\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_tensor)\n",
    "    keypoints = outputs['keypoints'].cpu().numpy()[0]\n",
    "    return keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ypose",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
